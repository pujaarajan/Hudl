{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os.path import join, isfile, dirname\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_load_sample_ratings(sampleRatingsFile):\n",
    "    \"\"\"\n",
    "    Parses a rating record in format user,highlight,rating.\n",
    "    \"\"\"\n",
    "    if not isfile(sampleRatingsFile):\n",
    "        print \"File %s does not exist.\" % sampleRatingsFile\n",
    "        sys.exit(1)\n",
    "    data = sc.textFile(sampleRatingsFile)\n",
    "    sample_user_highlights = data.map(lambda l: l.split(',')).map(lambda l: (int(l[0]), int(l[1])))\n",
    "    all_users = sample_user_highlights.map(lambda x: x[0]).distinct().zipWithIndex()\n",
    "    all_highlights = sample_user_highlights.map(lambda x: x[1]).distinct().zipWithIndex()\n",
    "    indexed_data = sample_user_highlights.leftOuterJoin(all_users) \\\n",
    "            .map(lambda x: x[1]) \\\n",
    "            .leftOuterJoin(all_highlights) \\\n",
    "            .map(lambda x: x[1])\n",
    "    sample_ratings = indexed_data.groupBy(lambda x: x) \\\n",
    "        .map(lambda x: Rating(x[0][0], x[0][1], 1))\n",
    "    if not sample_ratings:\n",
    "        print \"No sample ratings provided.\"\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return sample_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def parse_load_my_ratings(myRatingsFile):\n",
    "    \"\"\"\n",
    "    Parses a rating record in format user,highlight,rating.\n",
    "    \"\"\"\n",
    "    if not isfile(myRatingsFile):\n",
    "        print \"File %s does not exist.\" % myRatingsFile\n",
    "        sys.exit(1)\n",
    "    data = sc.textFile(myRatingsFile)    \n",
    "    my_ratings = data.map(lambda l: l.split(',')).map(lambda l: (int(l[0]), int(l[1])))\n",
    "    if not my_ratings:\n",
    "        print \"No my ratings provided.\"\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return my_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeRmse(model, data, n):\n",
    "    \"\"\"\n",
    "    Compute RMSE (Root Mean Squared Error).\n",
    "    \"\"\"\n",
    "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
    "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
    "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
    "    .values()\n",
    "    return sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_ratings_rdd = parse_load_sample_ratings(\"user_highlights.csv\")\n",
    "my_ratings_rdd = parse_load_my_ratings(\"my_ratings\")\n",
    "count_sample_ratings = sample_ratings_rdd.count()\n",
    "count_sample_users = sample_ratings_rdd.map(lambda r: r[0]).distinct().count()\n",
    "count_sample_highlights = sample_ratings_rdd.map(lambda r: r[1]).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 13721, validation: 4732, test: 4610\n"
     ]
    }
   ],
   "source": [
    "# split ratings into train (60%), validation (20%), and test (20%) based on the \n",
    "# last digit of the timestamp, add myRatings to train, and cache them\n",
    "# training, validation, test are all RDDs of (userId, movieId, rating)\n",
    "numPartitions = 4\n",
    "(training_data, validation_data, test_data) = sample_ratings_rdd.randomSplit([0.6, 0.2, 0.2])\n",
    "training_ratings = training_data\\\n",
    "    .repartition(numPartitions)\\\n",
    "    .cache()\n",
    "\n",
    "training_users = training_ratings.map(lambda x: x.user).distinct().map(lambda x: (x, 1))\n",
    "training_products = training_ratings.map(lambda x: x.product).distinct().map(lambda x: (x, 1))\n",
    "    \n",
    "validation_ratings = validation_data.repartition(numPartitions) \\\n",
    "    .map(lambda x: (x.user, x))\\\n",
    "    .join(training_users)\\\n",
    "    .map(lambda x: x[1][0])\\\n",
    "    .map(lambda x: (x.product, x))\\\n",
    "    .join(training_products)\\\n",
    "    .map(lambda x: x[1][0])\\\n",
    "    .cache()\n",
    "test_ratings = test_data.repartition(numPartitions)\\\n",
    "    .map(lambda x: (x.user, x))\\\n",
    "    .join(training_users)\\\n",
    "    .map(lambda x: x[1][0])\\\n",
    "    .map(lambda x: (x.product, x))\\\n",
    "    .join(training_products)\\\n",
    "    .map(lambda x: x[1][0])\\\n",
    "    .cache()\n",
    "training_count = training_data.count()\n",
    "validation_count = validation_data.count()\n",
    "test_count = test_data.count()\n",
    "print \"Training: %d, validation: %d, test: %d\" % (training_count, validation_count, test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (validation) = 0.236121 for the model trained with rank = 8, lambda = 0.1, and numIter = 10.\n",
      "RMSE (validation) = 0.236115 for the model trained with rank = 8, lambda = 0.1, and numIter = 20.\n",
      "RMSE (validation) = 0.236083 for the model trained with rank = 8, lambda = 10.0, and numIter = 10.\n",
      "RMSE (validation) = 0.236125 for the model trained with rank = 8, lambda = 10.0, and numIter = 20.\n",
      "RMSE (validation) = 0.236058 for the model trained with rank = 12, lambda = 0.1, and numIter = 10.\n",
      "RMSE (validation) = 0.235568 for the model trained with rank = 12, lambda = 0.1, and numIter = 20.\n",
      "RMSE (validation) = 0.235737 for the model trained with rank = 12, lambda = 10.0, and numIter = 10.\n",
      "RMSE (validation) = 0.235373 for the model trained with rank = 12, lambda = 10.0, and numIter = 20.\n"
     ]
    }
   ],
   "source": [
    "# train models and evaluate them on the validation set\n",
    "ranks = [8, 12]\n",
    "lambdas = [0.1, 10.0]\n",
    "numIters = [10, 20]\n",
    "bestModel = None\n",
    "bestValidationRmse = float(\"inf\")\n",
    "bestRank = 0\n",
    "bestLambda = -1.0\n",
    "bestNumIter = -1\n",
    "\n",
    "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
    "        model = ALS.trainImplicit(training_ratings, rank, numIter, alpha=0.01)\n",
    "        validationRmse = computeRmse(model, validation_ratings, validation_count)\n",
    "        print \"RMSE (validation) = %f for the model trained with \" % validationRmse + \\\n",
    "              \"rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter)\n",
    "        if (validationRmse < bestValidationRmse):\n",
    "            bestModel = model\n",
    "            bestValidationRmse = validationRmse\n",
    "            bestRank = rank\n",
    "            bestLambda = lmbda\n",
    "            bestNumIter = numIter\n",
    "testRmse = computeRmse(bestModel, test_ratings, test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was trained with rank = 12 and lambda = 10.0, and numIter = 20, and its RMSE on the test set is 0.234164.\n"
     ]
    }
   ],
   "source": [
    "# evaluate the best model on the test set\n",
    "print \"The best model was trained with rank = %d and lambda = %.1f, \" % (bestRank, bestLambda) \\\n",
    "      + \"and numIter = %d, and its RMSE on the test set is %f.\" % (bestNumIter, testRmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# compare the best model with a naive baseline that always returns the mean rating\n",
    "meanRating = training_ratings.union(validation_ratings).map(lambda x: x[2]).mean()\n",
    "baselineRmse = sqrt(test_ratings.map(lambda x: (meanRating - x[2]) ** 2).reduce(add) / test_count)\n",
    "#improvement = (baselineRmse - testRmse) / baselineRmse * 100\n",
    "#print \"The best model improves the baseline by %.2f\" % (improvement) + \"%.\"\n",
    "print meanRating \n",
    "print baselineRmse\n",
    "#print improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_personalized_recommendations(user_number):\n",
    "    # make personalized recommendations\n",
    "    data = sc.textFile(\"user_highlights.csv\")\n",
    "    sample_user_highlights = data.map(lambda l: l.split(',')).map(lambda l: (int(l[0]), int(l[1])))\n",
    "    all_users = sample_user_highlights.map(lambda x: x[0]).distinct().zipWithIndex()\n",
    "    all_highlights = sample_user_highlights.map(lambda x: x[1]).distinct().zipWithIndex()\n",
    "    indexed_data = sample_user_highlights.leftOuterJoin(all_users) \\\n",
    "    \n",
    "    user_list = all_users.collect()\n",
    "    user_dictionary =(dict((x, y) for x, y in user_list))\n",
    "    user_index = user_dictionary[user_number]\n",
    "    highlight_list = all_highlights.collect()\n",
    "    highlight_dictionary =(dict((y, x) for x, y in highlight_list))\n",
    "    recommendations = bestModel.call(\"recommendProducts\", user_index, 10)\n",
    "    print \"Highlights recommended for you:\"\n",
    "    for i in xrange(len(recommendations)):\n",
    "        print (\"%2d: %s\" % (i + 1, highlight_dictionary[recommendations[i][1]])).encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highlights recommended for you:\n",
      " 1: 208057095\n",
      " 2: 217712375\n",
      " 3: 213477376\n",
      " 4: 118520378\n",
      " 5: 198813381\n",
      " 6: 179148376\n",
      " 7: 98022386\n",
      " 8: 105772376\n",
      " 9: 217113552\n",
      "10: 133578378\n"
     ]
    }
   ],
   "source": [
    "make_personalized_recommendations(2981892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
